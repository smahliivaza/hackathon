{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "#from matting import load_path,load_data,load_alphamatting_data,load_validation_data\n",
    "import os\n",
    "from scipy import misc\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = 320\n",
    "train_batch_size = 1\n",
    "max_epochs = 1000000\n",
    "hard_mode = False\n",
    "\n",
    "#checkpoint file path\n",
    "pretrained_model = False\n",
    "#pretrained_model = False\n",
    "test_dir = './alhpamatting'\n",
    "test_outdir = './test_predict'\n",
    "#validation_dir = '/data/gezheng/data-matting/new2/validation'\n",
    "\n",
    "#pretrained_vgg_model_path\n",
    "model_path = './vgg16_weights.npz'\n",
    "log_dir = 'matting_log'\n",
    "\n",
    "dataset_alpha = 'train_data/alpha'\n",
    "dataset_eps = 'train_data/eps'\n",
    "dataset_BG = 'train_data/bg'\n",
    "\n",
    "paths_alpha,paths_eps,paths_BG = load_path(dataset_alpha,dataset_eps,dataset_BG,hard_mode = hard_mode)\n",
    "\n",
    "range_size = len(paths_alpha)\n",
    "print('range_size is %d' % range_size)\n",
    "#range_size/batch_size has to be int\n",
    "batchs_per_epoch = int(range_size/train_batch_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>!!!!!!!!!</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-73a7876ace60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindex_queue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange_input_producer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapacity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mindex_dequeue_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdequeue_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'index_dequeue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mraw_RGBs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "index_queue = tf.train.range_input_producer(range_size, num_epochs=None,shuffle=True, seed=None, capacity=32)\n",
    "index_dequeue_op = index_queue.dequeue_many(train_batch_size, 'index_dequeue')\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "image_batch = tf.placeholder(tf.float32, shape=(train_batch_size,image_size,image_size,3))\n",
    "raw_RGBs = tf.placeholder(tf.float32, shape=(train_batch_size,image_size,image_size,3))\n",
    "GT_matte_batch = tf.placeholder(tf.float32, shape = (train_batch_size,image_size,image_size,1))\n",
    "GT_trimap = tf.placeholder(tf.float32, shape = (train_batch_size,image_size,image_size,1))\n",
    "GTBG_batch = tf.placeholder(tf.float32, shape = (train_batch_size,image_size,image_size,3))\n",
    "GTFG_batch = tf.placeholder(tf.float32, shape = (train_batch_size,image_size,image_size,3))\n",
    "training = tf.placeholder(tf.bool)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "tf.add_to_collection('image_batch',image_batch)\n",
    "tf.add_to_collection('GT_trimap',GT_trimap)\n",
    "tf.add_to_collection('training',training)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "en_parameters = []\n",
    "pool_parameters = []\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "b_RGB = tf.identity(image_batch,name = 'b_RGB')\n",
    "b_trimap = tf.identity(GT_trimap,name = 'b_trimap')\n",
    "b_GTmatte = tf.identity(GT_matte_batch,name = 'b_GTmatte')\n",
    "b_GTBG = tf.identity(GTBG_batch,name = 'b_GTBG')\n",
    "b_GTFG = tf.identity(GTFG_batch,name = 'b_GTFG')\n",
    "\n",
    "tf.summary.image('GT_matte_batch',b_GTmatte,max_outputs = 5)\n",
    "tf.summary.image('trimap',b_trimap,max_outputs = 5)\n",
    "tf.summary.image('raw_RGBs',raw_RGBs,max_outputs = 5)\n",
    "\n",
    "b_input = tf.concat([b_RGB,b_trimap],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        activation = torch.nn.ReLU()\n",
    "        # conv1_1  \n",
    "        conv1_1 = torch.nn.Conv2d(in_channels = 4, \n",
    "                       out_channels = 64,\n",
    "                       kernel_size = [3, 3])\n",
    "        # conv1_2\n",
    "        conv1_2 = torch.nn.Conv2d(in_channels = 64, \n",
    "                       out_channels = 64,\n",
    "                       kernel_size = [3, 3])\n",
    "        # pool1\n",
    "        pool1 = torch.nn.MaxPool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "        # conv2_1\n",
    "        conv2_1 = torch.nn.Conv2d(in_channels = 64, \n",
    "                       out_channels = 128,\n",
    "                       kernel_size = [3, 3])\n",
    "        # conv2_2\n",
    "        conv2_2 = torch.nn.Conv2d(in_channels = 128, \n",
    "                       out_channels = 128,\n",
    "                       kernel_size = [3, 3])\n",
    "        # pool2\n",
    "        pool2 = torch.nn.MaxPool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "        # conv3_1\n",
    "        conv3_1 = torch.nn.Conv2d(in_channels = 128, \n",
    "                       out_channels = 256,\n",
    "                       kernel_size = [3, 3])\n",
    "        # conv3_2\n",
    "        conv3_2 = torch.nn.Conv2d(in_channels = 256, \n",
    "                       out_channels = 256,\n",
    "                       kernel_size = [3, 3])\n",
    "        # conv3_3\n",
    "        conv3_3 = torch.nn.Conv2d(in_channels = 256, \n",
    "                       out_channels = 256,\n",
    "                       kernel_size = [3, 3])\n",
    "        # pool3\n",
    "        pool3 = torch.nn.MaxPool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "        # conv4_1\n",
    "        conv4_1 = torch.nn.Conv2d(in_channels = 256, \n",
    "                       out_channels = 512,\n",
    "                       kernel_size = [3, 3])\n",
    "        # conv4_2\n",
    "        conv4_2 = torch.nn.Conv2d(in_channels = 512, \n",
    "                       out_channels = 512,\n",
    "                       kernel_size = [3, 3])\n",
    "        # conv4_3\n",
    "        conv4_3 = torch.nn.Conv2d(in_channels = 512, \n",
    "                       out_channels = 512,\n",
    "                       kernel_size = [3, 3])\n",
    "        # pool4\n",
    "        pool4 = torch.nn.MaxPool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "        # conv5_1\n",
    "        conv5_1 = torch.nn.Conv2d(in_channels = 512, \n",
    "                       out_channels = 512,\n",
    "                       kernel_size = [3, 3])\n",
    "        # conv5_2\n",
    "        conv5_2 = torch.nn.Conv2d(in_channels = 512, \n",
    "                       out_channels = 512,\n",
    "                       kernel_size = [3, 3])\n",
    "        # conv5_3\n",
    "        conv5_3 = torch.nn.Conv2d(in_channels = 512, \n",
    "                       out_channels = 512,\n",
    "                       kernel_size = [3, 3])\n",
    "        # pool5\n",
    "        pool5 = torch.nn.MaxPool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "        # conv6_1 \n",
    "        conv6_1 = torch.nn.Conv2d(in_channels = 512, \n",
    "                       out_channels = 4046,\n",
    "                       kernel_size = [7, 7])\n",
    "        \n",
    "        \n",
    "        # deconv6\n",
    "        deconv6 = torch.nn.ConvTranspose2d(in_channels = 4096, \n",
    "                             out_channels = 512, \n",
    "                             kernel_size = [1, 1])\n",
    "        batch_norm_6 = torch.nn.BatchNorm2d(num_features = 512)\n",
    "        # deconv5_1/unpooling\n",
    "        unpool_5 = torch.nn.MaxUnpool2d(kernel_size = [2, 2], \n",
    "                              stride = [2, 2])\n",
    "        # deconv5_2\n",
    "        deconv5_2 = torch.nn.ConvTranspose2d(in_channels = 512, \n",
    "                             out_channels = 512, \n",
    "                             kernel_size = [5, 5])\n",
    "        batch_norm_5 = torch.nn.BatchNorm2d(num_features = 512)\n",
    "        # deconv4_1/unpooling\n",
    "        unpool_4 = torch.nn.MaxUnpool2d(kernel_size = [2, 2], \n",
    "                              stride = [2, 2])\n",
    "        # deconv4_2\n",
    "        deconv4_2 = torch.nn.ConvTranspose2d(in_channels = 512, \n",
    "                             out_channels = 256, \n",
    "                             kernel_size = [5, 5])\n",
    "        batch_norm_4 = torch.nn.BatchNorm2d(num_features = 256)\n",
    "        # deconv3_1/unpooling\n",
    "        unpool_3 = torch.nn.MaxUnpool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "        # deconv3_2\n",
    "        deconv3_2 = torch.nn.ConvTranspose2d(in_channels = 256, \n",
    "                             out_channels = 128, \n",
    "                             kernel_size = [5, 5])\n",
    "        batch_norm_3 = torch.nn.BatchNorm2d(num_features = 128)\n",
    "        # deconv2_1/unpooling\n",
    "        unpool_2 = torch.nn.MaxUnpool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "        # deconv2_2\n",
    "        deconv2_2 = torch.nn.ConvTranspose2d(in_channels = 128, \n",
    "                             out_channels = 64, \n",
    "                             kernel_size = [5, 5])\n",
    "        batch_norm_2 = torch.nn.BatchNorm2d(num_features = 64)\n",
    "        # deconv1_1/unpooling\n",
    "        unpool_1 = torch.nn.MaxUnpool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "        # deconv1_2    \n",
    "        deconv1_2 = torch.nn.ConvTranspose2d(in_channels = 64, \n",
    "                             out_channels = 64, \n",
    "                             kernel_size = [5, 5])\n",
    "        batch_norm_1 = torch.nn.BatchNorm2d(num_features = 64)\n",
    "        # pred_alpha_matte\n",
    "        pred_alpha_matte = torch.nn.Conv2d(in_channels = 64, \n",
    "                        out_channels = 1, \n",
    "                        kernel_size = [5, 5])\n",
    "        act_sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "                                 \n",
    "                                 \n",
    "        \n",
    "    def forward(self, b_input):\n",
    "        # conv1_1  \n",
    "        x = conv1_1(b_input)\n",
    "        x = actiovation(x)\n",
    "            \n",
    "        # conv1_2\n",
    "        x = conv1_2(x)\n",
    "        x = actiovation(x)\n",
    "            \n",
    "        # pool1\n",
    "        x = pool1(x)\n",
    "            \n",
    "        # conv2_1\n",
    "        x = conv2_1(x)\n",
    "        x = actiovation(x)\n",
    "            \n",
    "        # conv2_2\n",
    "        x = conv2_2(x)\n",
    "        x = actiovation(x)\n",
    "            \n",
    "        # pool2\n",
    "        x = pool2(x)\n",
    "            \n",
    "        # conv3_1\n",
    "        x = conv3_1(x)\n",
    "        x = actiovation(x)\n",
    "            \n",
    "        # conv3_2\n",
    "        x = conv3_2(x)\n",
    "        x = actiovation(x)\n",
    "            \n",
    "        # conv3_3\n",
    "        x = conv3_3(x)\n",
    "        x = actiovation(x)\n",
    "            \n",
    "        # pool3\n",
    "        x = pool3(x)\n",
    "\n",
    "        # conv4_1\n",
    "        x = conv4_1(x)\n",
    "        x = actiovation(x)\n",
    "        \n",
    "        # conv4_2\n",
    "        x = conv4_2(x)\n",
    "        x = actiovation(x)\n",
    "        \n",
    "        # conv4_3\n",
    "        x = conv4_3(x)\n",
    "        x = actiovation(x)\n",
    "        \n",
    "        # pool4\n",
    "        x = pool4(x)\n",
    "        \n",
    "        # conv5_1\n",
    "        x = conv5_1(x)\n",
    "        x = actiovation(x)\n",
    "        \n",
    "        # conv5_2\n",
    "        x = conv5_2(x)\n",
    "        x = actiovation(x)\n",
    "        \n",
    "        # conv5_3\n",
    "        x = conv5_3(x)\n",
    "        x = actiovation(x)\n",
    "        \n",
    "        # pool5\n",
    "        x = pool5(x)\n",
    "        \n",
    "        # conv6_1 \n",
    "        x = conv6_1(x)\n",
    "        x = actiovation(x)\n",
    "        \n",
    "        \n",
    "        # deconv6\n",
    "        x = deconv6(x)\n",
    "        x = batch_norm_6(x)\n",
    "        x = activation(x)\n",
    "        \n",
    "        #deconv5_1/unpooling\n",
    "        x = unpool_5(x)\n",
    "                                            \n",
    "        # deconv5_2\n",
    "        x = deconv5_2(x)\n",
    "        x = batch_norm_5(x)\n",
    "        x = activation(x)\n",
    "        \n",
    "        # deconv4_1/unpooling)\n",
    "        x = unpool_4(x)\n",
    "        \n",
    "        # deconv4_2\n",
    "        x = deconv4_2(x)\n",
    "        x = batch_norm_4(x)\n",
    "        x = activation(x)\n",
    "        \n",
    "        # deconv3_1/unpooling\n",
    "        x = unpool_3(x)\n",
    "        \n",
    "        # deconv3_2\n",
    "        x = deconv3_2(x)\n",
    "        x = batch_norm_3(x)\n",
    "        x = activation(x)\n",
    "        \n",
    "        # deconv2_1/unpooling\n",
    "        x = unpool_2(x)\n",
    "        \n",
    "        # deconv2_2\n",
    "        x = deconv2_2(x)\n",
    "        x = batch_norm_2(x)\n",
    "        x = activation(x)\n",
    "        \n",
    "        # deconv1_1/unpooling\n",
    "        x = unpool_1(x)\n",
    "        \n",
    "        # deconv1_2  \n",
    "        x = deconv1_2(x)\n",
    "        x = batch_norm_1(x)\n",
    "        x = activation(x)\n",
    "        \n",
    "        # pred_alpha_matte\n",
    "        x = pred_alpha_matte(x)\n",
    "        pred_mattes = act_sigmoid(x)\n",
    "        \n",
    "        \"\"\"\n",
    "        ????????????????????????????\n",
    "        \"\"\"\n",
    "        return pred_mattes\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> create net</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>define loss and optimizer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wl = torch.where(torch.equal(b_trimap, 128), \n",
    "                 torch.Tensor([train_batch_size,image_size,image_size,1]).fill(1.),\n",
    "                 torch.Tensor([train_batch_size,image_size,image_size,1]).fill(0.))\n",
    "\n",
    "unknown_region_size = torch.sum(wl)\n",
    "\n",
    "alpha_diff = torch.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha_diff = tf.sqrt(tf.square(pred_mattes - GT_matte_batch) + 1e-12)\n",
    "\n",
    "p_RGB = []\n",
    "\n",
    "pred_mattes.set_shape([train_batch_size,image_size,image_size,1])\n",
    "b_GTBG.set_shape([train_batch_size,image_size,image_size,3])\n",
    "b_GTFG.set_shape([train_batch_size,image_size,image_size,3])\n",
    "\n",
    "raw_RGBs.set_shape([train_batch_size,image_size,image_size,3])\n",
    "b_GTmatte.set_shape([train_batch_size,image_size,image_size,1])\n",
    "\n",
    "pred_final =  tf.where(tf.equal(b_trimap,128), pred_mattes,b_trimap/255.0)\n",
    "tf.summary.image('pred_final',pred_final,max_outputs = 5)\n",
    "\n",
    "l_matte = tf.unstack(pred_final)\n",
    "BG = tf.unstack(b_GTBG)\n",
    "FG = tf.unstack(b_GTFG)\n",
    "\n",
    "for i in range(train_batch_size):\n",
    "    p_RGB.append(l_matte[i] * FG[i] + (tf.constant(1.) - l_matte[i]) * BG[i])\n",
    "pred_RGB = tf.stack(p_RGB)\n",
    "\n",
    "tf.summary.image('pred_RGB',pred_RGB,max_outputs = 5)\n",
    "c_diff = tf.sqrt(tf.square(pred_RGB - raw_RGBs) + 1e-12)/255.0\n",
    "\n",
    "alpha_loss = tf.reduce_sum(alpha_diff * wl)/(unknown_region_size)\n",
    "comp_loss = tf.reduce_sum(c_diff * wl)/(unknown_region_size)\n",
    "\n",
    "# tf.summary.image('alpha_diff',alpha_diff * wl_alpha,max_outputs = 5)\n",
    "# tf.summary.image('c_diff',c_diff * wl_RGB,max_outputs = 5)\n",
    "\n",
    "tf.summary.scalar('alpha_loss',alpha_loss)\n",
    "tf.summary.scalar('comp_loss',comp_loss)\n",
    "\n",
    "total_loss = (alpha_loss + comp_loss) * 0.5\n",
    "tf.summary.scalar('total_loss',total_loss)\n",
    "global_step = tf.Variable(0,trainable=False)\n",
    "\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate = 1e-5).minimize(total_loss,global_step = global_step)\n",
    "\n",
    "saver = tf.train.Saver(tf.trainable_variables() , max_to_keep = 1)\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "summary_op = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter(log_dir, tf.get_default_graph())\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.6)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options = gpu_options)) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf.train.start_queue_runners(coord=coord,sess=sess)\n",
    "    batch_num = 0\n",
    "    epoch_num = 0\n",
    "    #initialize all parameters in vgg16\n",
    "    if not pretrained_model:\n",
    "        weights = np.load(model_path)\n",
    "        keys = sorted(weights.keys())\n",
    "        for i, k in enumerate(keys):\n",
    "            if i == 28:\n",
    "                break\n",
    "            if k == 'conv1_1_W':  \n",
    "                sess.run(en_parameters[i].assign(np.concatenate([weights[k],np.zeros([3,3,1,64])],axis = 2)))\n",
    "            else:\n",
    "                if k=='fc6_W':\n",
    "                    tmp = np.reshape(weights[k],(7,7,512,4096))\n",
    "                    sess.run(en_parameters[i].assign(tmp))\n",
    "                else:\n",
    "                    sess.run(en_parameters[i].assign(weights[k]))\n",
    "        print('finish loading vgg16 model')\n",
    "    else:\n",
    "        print('Restoring pretrained model...')\n",
    "        saver.restore(sess,tf.train.latest_checkpoint('./model'))\n",
    "    sess.graph.finalize()\n",
    "\n",
    "    while epoch_num < max_epochs:  \n",
    "        while batch_num < batchs_per_epoch:\n",
    "            batch_index = sess.run(index_dequeue_op)\n",
    "\n",
    "            batch_alpha_paths = paths_alpha[batch_index]\n",
    "            batch_eps_paths = paths_eps[batch_index]\n",
    "            batch_BG_paths = paths_BG[batch_index]\n",
    "            batch_RGBs,batch_trimaps,batch_alphas,batch_BGs,batch_FGs,RGBs_with_mean = load_data(batch_alpha_paths,batch_eps_paths,batch_BG_paths)\n",
    "\n",
    "            feed = {image_batch:batch_RGBs, GT_matte_batch:batch_alphas,GT_trimap:batch_trimaps, GTBG_batch:batch_BGs, GTFG_batch:batch_FGs,raw_RGBs:RGBs_with_mean,training:True}\n",
    "\n",
    "            _,loss,summary_str,step= sess.run([train_op,total_loss,summary_op,global_step],feed_dict = feed)\n",
    "            print('epoch %d   batch %d   loss is %f' %(epoch_num,batch_num,loss))\n",
    "\n",
    "            if step%200 == 0:\n",
    "                print('saving model......')\n",
    "                saver.save(sess,'./model/model.ckpt',global_step = step, write_meta_graph = False)\n",
    "\n",
    "                print('test on validation data...')\n",
    "                test_RGBs,test_trimaps,test_alphas,all_shape,image_paths,trimap_size = load_alphamatting_data(test_dir)\n",
    "                vali_diff = []\n",
    "                \n",
    "                for i in range(len(test_RGBs)):\n",
    "                    test_RGB = np.expand_dims(test_RGBs[i],0)\n",
    "                    test_trimap = np.expand_dims(test_trimaps[i],0)\n",
    "                    test_alpha = test_alphas[i]\n",
    "                    shape_i = all_shape[i]\n",
    "                    image_path = image_paths[i]\n",
    "                    \n",
    "                    feed = {image_batch:test_RGB,GT_trimap:test_trimap,training:False}\n",
    "                    test_out = sess.run(pred_final,feed_dict = feed)\n",
    "                    \n",
    "                    i_out = misc.imresize(test_out[0,:,:,0],shape_i)\n",
    "                    vali_diff.append(np.sum(np.abs(i_out/255.0-test_alpha))/trimap_size[i])\n",
    "                    misc.imsave(os.path.join(test_outdir,image_path),i_out)\n",
    "                \n",
    "                vali_loss = np.mean(vali_diff)\n",
    "                print('validation loss is '+ str(vali_loss))\n",
    "                validation_summary = tf.Summary()\n",
    "                validation_summary.value.add(tag='validation_loss',simple_value = vali_loss)\n",
    "                summary_writer.add_summary(validation_summary,step)\n",
    "\n",
    "            summary_writer.add_summary(summary_str,global_step = step)\n",
    "            batch_num += 1\n",
    "        batch_num = 0\n",
    "        epoch_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conv1_1\n",
    "\n",
    "\"\"\"\n",
    "with tf.name_scope('conv1_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 4, 64], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(b_input, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    conv1_1 = tf.nn.relu(out, name=scope)\n",
    "    en_parameters += [kernel, biases]\n",
    "\"\"\"    \n",
    "conv = torch.nn.Conv2d(in_channels = 4, \n",
    "                       out_channels = 64,\n",
    "                       kernel_size = [3, 3])\n",
    "x = conv(b_input)\n",
    "activation = torch.nn.ReLU()\n",
    "x = actiovation(x)\n",
    "\n",
    "\n",
    "# conv1_2\n",
    "\"\"\"\n",
    "with tf.name_scope('conv1_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 64], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv1_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    conv1_2 = tf.nn.relu(out, name=scope)\n",
    "    en_parameters += [kernel, biases]\n",
    "\"\"\"\n",
    "conv = torch.nn.Conv2d(in_channels = 64, \n",
    "                       out_channels = 64,\n",
    "                       kernel_size = [3, 3])\n",
    "x = conv(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = actiovation(x)\n",
    "\n",
    "\n",
    "\n",
    "# pool1\n",
    "'''\n",
    "pool1,arg1 = tf.nn.max_pool_with_argmax(conv1_2,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1],padding='SAME',name='pool1')\n",
    "pool_parameters.append(arg1)\n",
    "'''\n",
    "max_pool = torch.nn.MaxPool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "x = max_pool(x)\n",
    "\n",
    "\n",
    "# conv2_1\n",
    "\"\"\"\n",
    "with tf.name_scope('conv2_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 64, 128], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    conv2_1 = tf.nn.relu(out, name=scope)\n",
    "    en_parameters += [kernel, biases]\n",
    "\"\"\"\n",
    "conv = torch.nn.Conv2d(in_channels = 64, \n",
    "                       out_channels = 128,\n",
    "                       kernel_size = [3, 3])\n",
    "x = conv(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = actiovation(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# conv2_2\n",
    "\"\"\"\n",
    "with tf.name_scope('conv2_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 128], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv2_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    conv2_2 = tf.nn.relu(out, name=scope)\n",
    "    en_parameters += [kernel, biases]\n",
    "\"\"\"\n",
    "conv = torch.nn.Conv2d(in_channels = 128, \n",
    "                       out_channels = 128,\n",
    "                       kernel_size = [3, 3])\n",
    "x = conv(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = actiovation(x)\n",
    "\n",
    "\n",
    "\n",
    "# pool2\n",
    "\"\"\"\n",
    "pool2,arg2 = tf.nn.max_pool_with_argmax(conv2_2,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1],padding='SAME',name='pool2')\n",
    "pool_parameters.append(arg2)\n",
    "\"\"\"\n",
    "max_pool = torch.nn.MaxPool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "x = max_pool(x)\n",
    "\n",
    "\n",
    "# conv3_1\n",
    "\"\"\"\n",
    "with tf.name_scope('conv3_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 128, 256], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(pool2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    conv3_1 = tf.nn.relu(out, name=scope)\n",
    "    en_parameters += [kernel, biases]\n",
    "\"\"\"\n",
    "conv = torch.nn.Conv2d(in_channels = 128, \n",
    "                       out_channels = 256,\n",
    "                       kernel_size = [3, 3])\n",
    "x = conv(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = actiovation(x)\n",
    "\n",
    "\n",
    "# conv3_2\n",
    "\"\"\"\n",
    "with tf.name_scope('conv3_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv3_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    conv3_2 = tf.nn.relu(out, name=scope)\n",
    "    en_parameters += [kernel, biases]\n",
    "\"\"\"\n",
    "conv = torch.nn.Conv2d(in_channels = 256, \n",
    "                       out_channels = 256,\n",
    "                       kernel_size = [3, 3])\n",
    "x = conv(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = actiovation(x)\n",
    "\n",
    "\n",
    "\n",
    "# conv3_3\n",
    "\"\"\"\n",
    "with tf.name_scope('conv3_3') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv3_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    conv3_3 = tf.nn.relu(out, name=scope)\n",
    "    en_parameters += [kernel, biases]\n",
    "\"\"\"\n",
    "conv = torch.nn.Conv2d(in_channels = 256, \n",
    "                       out_channels = 256,\n",
    "                       kernel_size = [3, 3])\n",
    "x = conv(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = actiovation(x)\n",
    "\n",
    "\n",
    "# pool3\n",
    "\"\"\"\n",
    "pool3,arg3 = tf.nn.max_pool_with_argmax(conv3_3,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1],padding='SAME',name='pool3')\n",
    "pool_parameters.append(arg3)\n",
    "\"\"\"\n",
    "max_pool = torch.nn.MaxPool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "x = max_pool(x)\n",
    "\n",
    "\n",
    "# conv4_1\n",
    "\"\"\"\n",
    "with tf.name_scope('conv4_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 512], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(pool3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    conv4_1 = tf.nn.relu(out, name=scope)\n",
    "    en_parameters += [kernel, biases]\n",
    "\"\"\"\n",
    "conv = torch.nn.Conv2d(in_channels = 256, \n",
    "                       out_channels = 512,\n",
    "                       kernel_size = [3, 3])\n",
    "x = conv(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = actiovation(x)\n",
    "\n",
    "\n",
    "\n",
    "# conv4_2\n",
    "\"\"\"\n",
    "with tf.name_scope('conv4_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv4_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    conv4_2 = tf.nn.relu(out, name=scope)\n",
    "    en_parameters += [kernel, biases]\n",
    "\"\"\"\n",
    "conv = torch.nn.Conv2d(in_channels = 512, \n",
    "                       out_channels = 512,\n",
    "                       kernel_size = [3, 3])\n",
    "x = conv(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = actiovation(x)\n",
    "\n",
    "\n",
    "# conv4_3\n",
    "\"\"\"\n",
    "with tf.name_scope('conv4_3') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv4_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    conv4_3 = tf.nn.relu(out, name=scope)\n",
    "    en_parameters += [kernel, biases]\n",
    "\"\"\"\n",
    "conv = torch.nn.Conv2d(in_channels = 512, \n",
    "                       out_channels = 512,\n",
    "                       kernel_size = [3, 3])\n",
    "x = conv(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = actiovation(x)\n",
    "\n",
    "\n",
    "# pool4\n",
    "\"\"\"\n",
    "pool4,arg4 = tf.nn.max_pool_with_argmax(conv4_3,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1],padding='SAME',name='pool4')\n",
    "pool_parameters.append(arg4)\n",
    "\"\"\"\n",
    "max_pool = torch.nn.MaxPool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "x = max_pool(x)\n",
    "\n",
    "\n",
    "# conv5_1\n",
    "\"\"\"\n",
    "with tf.name_scope('conv5_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                         stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(pool4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                     trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    conv5_1 = tf.nn.relu(out, name=scope)\n",
    "    en_parameters += [kernel, biases]\n",
    "\"\"\"\n",
    "conv = torch.nn.Conv2d(in_channels = 512, \n",
    "                       out_channels = 512,\n",
    "                       kernel_size = [3, 3])\n",
    "x = conv(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = actiovation(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# conv5_2\n",
    "\"\"\"\n",
    "with tf.name_scope('conv5_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv5_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    conv5_2 = tf.nn.relu(out, name=scope)\n",
    "    en_parameters += [kernel, biases]\n",
    "\"\"\"\n",
    "conv = torch.nn.Conv2d(in_channels = 512, \n",
    "                       out_channels = 512,\n",
    "                       kernel_size = [3, 3])\n",
    "x = conv(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = actiovation(x)\n",
    "\n",
    "\n",
    "\n",
    "# conv5_3\n",
    "\"\"\"\n",
    "with tf.name_scope('conv5_3') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([3, 3, 512, 512], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv5_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    conv5_3 = tf.nn.relu(out, name=scope)\n",
    "    en_parameters += [kernel, biases]\n",
    "\"\"\"\n",
    "conv = torch.nn.Conv2d(in_channels = 512, \n",
    "                       out_channels = 512,\n",
    "                       kernel_size = [3, 3])\n",
    "x = conv(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = actiovation(x)\n",
    "\n",
    "\n",
    "\n",
    "# pool5\n",
    "\"\"\"\n",
    "pool5,arg5 = tf.nn.max_pool_with_argmax(conv5_3,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1],padding='SAME',name='pool5')\n",
    "pool_parameters.append(arg5)\n",
    "\"\"\"\n",
    "max_pool = torch.nn.MaxPool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "x = max_pool(x)\n",
    "\n",
    "\n",
    "\n",
    "# conv6_1\n",
    "\"\"\"\n",
    "with tf.name_scope('conv6_1') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([7, 7, 512, 4096], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(pool5, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[4096], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    conv6_1 = tf.nn.relu(out, name='conv6_1')\n",
    "    en_parameters += [kernel, biases]  \n",
    "\"\"\"    \n",
    "conv = torch.nn.Conv2d(in_channels = 512, \n",
    "                       out_channels = 4046,\n",
    "                       kernel_size = [7, 7])\n",
    "x = conv(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = actiovation(x)\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#deconv6\n",
    "\n",
    "\"\"\"\n",
    "with tf.variable_scope('deconv6') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([1, 1, 4096, 512], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(conv6_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    deconv6 = tf.nn.relu(tf.layers.batch_normalization(out,training=training), name='deconv6')\n",
    "\"\"\"\n",
    "deconv = torch.nn.ConvTranspose2d(in_channels = 4096, \n",
    "                             out_channels = 512, \n",
    "                             kernel_size = [1, 1])\n",
    "x = deconv(x)\n",
    "batch_norm = torch.nn.BatchNorm2d(num_features = 512)\n",
    "x = batch_norm(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = activation(x)\n",
    "\n",
    "\n",
    "\n",
    "#deconv5_1/unpooling\n",
    "\"\"\"\n",
    "deconv5_1 = unpool(deconv6,pool_parameters[-1])\n",
    "\"\"\"\n",
    "unpool = torch.nn.MaxUnpool2d(kernel_size = [2, 2], \n",
    "                              stride = [2, 2])\n",
    "x = unpool(x)\n",
    "\n",
    "\n",
    "#deconv5_2\n",
    "\"\"\"\n",
    "with tf.variable_scope('deconv5_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([5, 5, 512, 512], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(deconv5_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[512], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    deconv5_2 = tf.nn.relu(tf.layers.batch_normalization(out,training=training), name='deconv5_2')\n",
    "\"\"\"\n",
    "deconv = torch.nn.ConvTranspose2d(in_channels = 512, \n",
    "                             out_channels = 512, \n",
    "                             kernel_size = [5, 5])\n",
    "x = deconv(x)\n",
    "batch_norm = torch.nn.BatchNorm2d(num_features = 512)\n",
    "x = batch_norm(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = activation(x)\n",
    "\n",
    "\n",
    "\n",
    "#deconv4_1/unpooling\n",
    "\"\"\"\n",
    "deconv4_1 = unpool(deconv5_2,pool_parameters[-2])\n",
    "\"\"\"\n",
    "unpool = torch.nn.MaxUnpool2d(kernel_size = [2, 2], \n",
    "                              stride = [2, 2])\n",
    "x = unpool(x)\n",
    "\n",
    "\n",
    "#deconv4_2\n",
    "\"\"\"\n",
    "with tf.variable_scope('deconv4_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([5, 5, 512, 256], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(deconv4_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    deconv4_2 = tf.nn.relu(tf.layers.batch_normalization(out,training=training), name='deconv4_2')\n",
    "\"\"\"\n",
    "deconv = torch.nn.ConvTranspose2d(in_channels = 512, \n",
    "                             out_channels = 256, \n",
    "                             kernel_size = [5, 5])\n",
    "x = deconv(x)\n",
    "batch_norm = torch.nn.BatchNorm2d(num_features = 256)\n",
    "x = batch_norm(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = activation(x)\n",
    "\n",
    "\n",
    "\n",
    "#deconv3_1/unpooling\n",
    "\"\"\"\n",
    "deconv3_1 = unpool(deconv4_2,pool_parameters[-3])\n",
    "\"\"\"\n",
    "unpool = torch.nn.MaxUnpool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "x = unpool(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#deconv3_2\n",
    "\"\"\"\n",
    "with tf.variable_scope('deconv3_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([5, 5, 256, 128], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(deconv3_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[128], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    deconv3_2 = tf.nn.relu(tf.layers.batch_normalization(out,training=training), name='deconv3_2')\n",
    "\"\"\"\n",
    "deconv = torch.nn.ConvTranspose2d(in_channels = 256, \n",
    "                             out_channels = 128, \n",
    "                             kernel_size = [5, 5])\n",
    "x = deconv(x)\n",
    "batch_norm = torch.nn.BatchNorm2d(num_features = 128)\n",
    "x = batch_norm(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = activation(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#deconv2_1/unpooling\n",
    "\"\"\"\n",
    "deconv2_1 = unpool(deconv3_2,pool_parameters[-4])\n",
    "\"\"\"\n",
    "unpool = torch.nn.MaxUnpool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "x = unpool(x)\n",
    "\n",
    "\n",
    "#deconv2_2\n",
    "\"\"\"\n",
    "with tf.variable_scope('deconv2_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([5, 5, 128, 64], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(deconv2_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    deconv2_2 = tf.nn.relu(tf.layers.batch_normalization(out,training=training), name='deconv2_2')\n",
    "\"\"\"\n",
    "deconv = torch.nn.ConvTranspose2d(in_channels = 128, \n",
    "                             out_channels = 64, \n",
    "                             kernel_size = [5, 5])\n",
    "x = deconv(x)\n",
    "batch_norm = torch.nn.BatchNorm2d(num_features = 64)\n",
    "x = batch_norm(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = activation(x)\n",
    "\n",
    "\n",
    "#deconv1_1/unpooling\n",
    "\"\"\"\n",
    "deconv1_1 = unpool(deconv2_2,pool_parameters[-5])\n",
    "\"\"\"\n",
    "unpool = torch.nn.MaxUnpool2d(kernel_size = [2, 2], \n",
    "                       stride = [2, 2])\n",
    "x = unpool(x)\n",
    "\n",
    "\n",
    "#deconv1_2\n",
    "\"\"\"\"\n",
    "with tf.variable_scope('deconv1_2') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([5, 5, 64, 64], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(deconv1_1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    deconv1_2 = tf.nn.relu(tf.layers.batch_normalization(out,training=training), name='deconv1_2')\n",
    "\"\"\"\"    \n",
    "deconv = torch.nn.ConvTranspose2d(in_channels = 64, \n",
    "                             out_channels = 64, \n",
    "                             kernel_size = [5, 5])\n",
    "x = deconv(x)\n",
    "batch_norm = torch.nn.BatchNorm2d(num_features = 64)\n",
    "x = batch_norm(x)\n",
    "activation = torch.nn.ReLU()\n",
    "x = activation(x)\n",
    " \n",
    "    \n",
    "    \n",
    "# pred_alpha_matte\n",
    "\"\"\"\n",
    "with tf.variable_scope('pred_alpha') as scope:\n",
    "    kernel = tf.Variable(tf.truncated_normal([5, 5, 64, 1], dtype=tf.float32,\n",
    "                                             stddev=1e-1), name='weights')\n",
    "    conv = tf.nn.conv2d(deconv1_2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.Variable(tf.constant(0.0, shape=[1], dtype=tf.float32),\n",
    "                         trainable=True, name='biases')\n",
    "    out = tf.nn.bias_add(conv, biases)\n",
    "    pred_mattes = tf.nn.sigmoid(out)   \n",
    "\"\"\"\n",
    "conv = torch.nn.Conv2d(in_channels = 64, \n",
    "                        out_channels = 1, \n",
    "                        kernel_size = [5, 5])\n",
    "x = conv(x)\n",
    "act_sigmoid = torch.nn.Sigmoid()\n",
    "pred_mattes = act_sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.add_to_collection(\"pred_mattes\", pred_mattes)\n",
    "\n",
    "wl = tf.where(tf.equal(b_trimap,128),tf.fill([train_batch_size,image_size,image_size,1],1.),tf.fill([train_batch_size,image_size,image_size,1],0.))\n",
    "unknown_region_size = tf.reduce_sum(wl)\n",
    "\n",
    "tf.summary.image('pred_mattes',pred_mattes,max_outputs = 5)\n",
    "alpha_diff = tf.sqrt(tf.square(pred_mattes - GT_matte_batch)+ 1e-12)\n",
    "\n",
    "p_RGB = []\n",
    "pred_mattes.set_shape([train_batch_size,image_size,image_size,1])\n",
    "b_GTBG.set_shape([train_batch_size,image_size,image_size,3])\n",
    "b_GTFG.set_shape([train_batch_size,image_size,image_size,3])\n",
    "raw_RGBs.set_shape([train_batch_size,image_size,image_size,3])\n",
    "b_GTmatte.set_shape([train_batch_size,image_size,image_size,1])\n",
    "\n",
    "pred_final =  tf.where(tf.equal(b_trimap,128), pred_mattes,b_trimap/255.0)\n",
    "tf.summary.image('pred_final',pred_final,max_outputs = 5)\n",
    "\n",
    "l_matte = tf.unstack(pred_final)\n",
    "BG = tf.unstack(b_GTBG)\n",
    "FG = tf.unstack(b_GTFG)\n",
    "\n",
    "for i in range(train_batch_size):\n",
    "    p_RGB.append(l_matte[i] * FG[i] + (tf.constant(1.) - l_matte[i]) * BG[i])\n",
    "pred_RGB = tf.stack(p_RGB)\n",
    "\n",
    "tf.summary.image('pred_RGB',pred_RGB,max_outputs = 5)\n",
    "c_diff = tf.sqrt(tf.square(pred_RGB - raw_RGBs) + 1e-12)/255.0\n",
    "\n",
    "alpha_loss = tf.reduce_sum(alpha_diff * wl)/(unknown_region_size)\n",
    "comp_loss = tf.reduce_sum(c_diff * wl)/(unknown_region_size)\n",
    "\n",
    "# tf.summary.image('alpha_diff',alpha_diff * wl_alpha,max_outputs = 5)\n",
    "# tf.summary.image('c_diff',c_diff * wl_RGB,max_outputs = 5)\n",
    "\n",
    "tf.summary.scalar('alpha_loss',alpha_loss)\n",
    "tf.summary.scalar('comp_loss',comp_loss)\n",
    "\n",
    "total_loss = (alpha_loss + comp_loss) * 0.5\n",
    "tf.summary.scalar('total_loss',total_loss)\n",
    "global_step = tf.Variable(0,trainable=False)\n",
    "\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate = 1e-5).minimize(total_loss,global_step = global_step)\n",
    "\n",
    "saver = tf.train.Saver(tf.trainable_variables() , max_to_keep = 1)\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "summary_op = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter(log_dir, tf.get_default_graph())\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.6)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options = gpu_options)) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    tf.train.start_queue_runners(coord=coord,sess=sess)\n",
    "    batch_num = 0\n",
    "    epoch_num = 0\n",
    "    #initialize all parameters in vgg16\n",
    "    if not pretrained_model:\n",
    "        weights = np.load(model_path)\n",
    "        keys = sorted(weights.keys())\n",
    "        for i, k in enumerate(keys):\n",
    "            if i == 28:\n",
    "                break\n",
    "            if k == 'conv1_1_W':  \n",
    "                sess.run(en_parameters[i].assign(np.concatenate([weights[k],np.zeros([3,3,1,64])],axis = 2)))\n",
    "            else:\n",
    "                if k=='fc6_W':\n",
    "                    tmp = np.reshape(weights[k],(7,7,512,4096))\n",
    "                    sess.run(en_parameters[i].assign(tmp))\n",
    "                else:\n",
    "                    sess.run(en_parameters[i].assign(weights[k]))\n",
    "        print('finish loading vgg16 model')\n",
    "    else:\n",
    "        print('Restoring pretrained model...')\n",
    "        saver.restore(sess,tf.train.latest_checkpoint('./model'))\n",
    "    sess.graph.finalize()\n",
    "\n",
    "    while epoch_num < max_epochs:  \n",
    "        while batch_num < batchs_per_epoch:\n",
    "            batch_index = sess.run(index_dequeue_op)\n",
    "\n",
    "            batch_alpha_paths = paths_alpha[batch_index]\n",
    "            batch_eps_paths = paths_eps[batch_index]\n",
    "            batch_BG_paths = paths_BG[batch_index]\n",
    "            batch_RGBs,batch_trimaps,batch_alphas,batch_BGs,batch_FGs,RGBs_with_mean = load_data(batch_alpha_paths,batch_eps_paths,batch_BG_paths)\n",
    "\n",
    "            feed = {image_batch:batch_RGBs, GT_matte_batch:batch_alphas,GT_trimap:batch_trimaps, GTBG_batch:batch_BGs, GTFG_batch:batch_FGs,raw_RGBs:RGBs_with_mean,training:True}\n",
    "\n",
    "            _,loss,summary_str,step= sess.run([train_op,total_loss,summary_op,global_step],feed_dict = feed)\n",
    "            print('epoch %d   batch %d   loss is %f' %(epoch_num,batch_num,loss))\n",
    "\n",
    "            if step%200 == 0:\n",
    "                print('saving model......')\n",
    "                saver.save(sess,'./model/model.ckpt',global_step = step, write_meta_graph = False)\n",
    "\n",
    "                print('test on validation data...')\n",
    "                test_RGBs,test_trimaps,test_alphas,all_shape,image_paths,trimap_size = load_alphamatting_data(test_dir)\n",
    "                vali_diff = []\n",
    "                \n",
    "                for i in range(len(test_RGBs)):\n",
    "                    test_RGB = np.expand_dims(test_RGBs[i],0)\n",
    "                    test_trimap = np.expand_dims(test_trimaps[i],0)\n",
    "                    test_alpha = test_alphas[i]\n",
    "                    shape_i = all_shape[i]\n",
    "                    image_path = image_paths[i]\n",
    "                    \n",
    "                    feed = {image_batch:test_RGB,GT_trimap:test_trimap,training:False}\n",
    "                    test_out = sess.run(pred_final,feed_dict = feed)\n",
    "                    \n",
    "                    i_out = misc.imresize(test_out[0,:,:,0],shape_i)\n",
    "                    vali_diff.append(np.sum(np.abs(i_out/255.0-test_alpha))/trimap_size[i])\n",
    "                    misc.imsave(os.path.join(test_outdir,image_path),i_out)\n",
    "                \n",
    "                vali_loss = np.mean(vali_diff)\n",
    "                print('validation loss is '+ str(vali_loss))\n",
    "                validation_summary = tf.Summary()\n",
    "                validation_summary.value.add(tag='validation_loss',simple_value = vali_loss)\n",
    "                summary_writer.add_summary(validation_summary,step)\n",
    "\n",
    "            summary_writer.add_summary(summary_str,global_step = step)\n",
    "            batch_num += 1\n",
    "        batch_num = 0\n",
    "        epoch_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
