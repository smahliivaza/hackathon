{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch, json, pickle\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from os import path, listdir\n",
    "\n",
    "from encoder import DataEncoder\n",
    "from .bbox import BoundingBox\n",
    "\n",
    "\n",
    "class BottleLoader(Dataset):\n",
    "    def __init__(self, dir, encoder, json_suffix='', transform=None, val=False):\n",
    "        self.dir = dir\n",
    "        self.encoder = DataEncoder()\n",
    "        self.json_suffix = json_suffix\n",
    "        self.transform = transform\n",
    "        self.encoder = encoder\n",
    "        \n",
    "        files = listdir(self.dir)\n",
    "        prefixes = list(map(lambda f: f.replace('.jpg', ''), \n",
    "                            filter(lambda f: '.jpg' in f, files)))\n",
    "        prefixes = list(map(lambda f: path.join(self.dir, f), prefixes))\n",
    "        \n",
    "        self.impath = list(map(lambda f: f'{f}.jpg', prefixes))\n",
    "        self.annotations = list(map(lambda f: f'{f}{self.json_suffix}.json', prefixes))\n",
    "      \n",
    "        labelset = set()\n",
    "        for p in self.annotations:\n",
    "            with open(p, 'r') as f:\n",
    "                j = json.load(f)\n",
    "            labelset = labelset.union(set(map(lambda f: f['id'], j)))\n",
    "        self.label_index = dict((k,v) for v,k in enumerate(labelset))\n",
    "        \n",
    "        self.val = val\n",
    "        \n",
    "    def annotate(self, fname, imsize):\n",
    "        boxes = []\n",
    "        with open(fname, 'r') as f:\n",
    "            groups = json.load(f)\n",
    "        coords, labels = [], []\n",
    "        for group in groups:\n",
    "            for obj in group['data']:\n",
    "                boxes.append(BoundingBox(\n",
    "                    obj['boundingBox']['X'], \n",
    "                    obj['boundingBox']['Y'] + obj['boundingBox']['Height'], \n",
    "                    obj['boundingBox']['X'] + obj['boundingBox']['Width'], \n",
    "                    obj['boundingBox']['Y'], imsize[0], imsize[1], \n",
    "                    self.label_index[group['id']]))\n",
    "        return boxes\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        data = list(self.metadata['paths'][i])\n",
    "        shape = self.metadata['shape'][i]\n",
    "        img = np.array(Image.open(data[0]))\n",
    "        img = resize(img, (sizeremap[shape[0]], sizeremap[shape[1]]))\n",
    "        img = torch.Tensor(img.transpose(2,0,1))\n",
    "\n",
    "        coords = torch.Tensor(np.stack(coords))\n",
    "        labels = torch.LongTensor(np.array(\n",
    "            list(map(self.metadata['label_index'].get, labels)))\n",
    "        ).view(-1,1)\n",
    "        return img, coords, labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        impath = self.impath[index]\n",
    "        annotation = self.annotations[index]\n",
    "        image = Image.open(impath)\n",
    "        boxes = self.annotate(annotation, image.size)\n",
    "        example = {'image': image, 'boxes': boxes}\n",
    "        if self.transform:\n",
    "            example = self.transform(example)\n",
    "        return example\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.impath)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        imgs = [example['image'] for example in batch]\n",
    "        boxes  = [example['boxes'] for example in batch]\n",
    "        labels = [example['labels'] for example in batch]\n",
    "        img_sizes = [img.size()[1:] for img in imgs]\n",
    "\n",
    "        max_h = max([im.size(1) for im in imgs])\n",
    "        max_w = max([im.size(2) for im in imgs])\n",
    "        num_imgs = len(imgs)\n",
    "        inputs = torch.zeros(num_imgs, 3, max_h, max_w)\n",
    "\n",
    "        loc_targets = []\n",
    "        cls_targets = []\n",
    "        for i in range(num_imgs):\n",
    "            im = imgs[i]\n",
    "            imh, imw = im.size(1), im.size(2)\n",
    "            inputs[i,:,:imh,:imw] = im\n",
    "\n",
    "            loc_target, cls_target = self.encoder.encode(boxes[i], labels[i], input_size=(max_w, max_h))\n",
    "            loc_targets.append(loc_target)\n",
    "            cls_targets.append(cls_target)\n",
    "        if not self.val:\n",
    "            return inputs, torch.stack(loc_targets), torch.stack(cls_targets)\n",
    "return inputs, img_sizes, torch.stack(loc_targets), torch.stack(cls_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy import misc,ndimage\n",
    "import copy\n",
    "import itertools\n",
    "import os\n",
    "from sys import getrefcount\n",
    "import gc\n",
    "import sys\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch, json, pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from os import path, listdir\n",
    "from encoder import DataEncoder\n",
    "from .bbox import BoundingBox\n",
    "\n",
    "\n",
    "trimap_kernel = [val for val in range(20,40)]\n",
    "g_mean = np.array(([126.88,120.24,112.19])).reshape([1,1,3])\n",
    "\n",
    "hard_samples = [\n",
    "1,4,8,11,13,15,16,19,28,42,43,44,46,65,68,69,70,81,91,92,94,101,104,\n",
    "118,137,145,152,155,156,176,187,189,191,193,198,203,208,212,215,\n",
    "216,221,233,239,243,254,264,265,267,272,278,279,281,288,290,291,292,\n",
    "293,298,300,301,302,309,316,320,325,337,345,346,347,369,370,374,381,\n",
    "386,402,416,432,443,450,451,454,456,457,459,464,487,490,499,502,513,\n",
    "514,552,555,558,559,577,580,587,593,602,608,609,613,632,634,639,640,\n",
    "649,663,688,710,717,718,723,729,736,740,741,745,757,769,775,778,785,\n",
    "788,805,808,815,820,834,839,840,845,846,848,860,861,864,868,870,872,\n",
    "877,885,889,892,894,895\n",
    "]\n",
    "\n",
    "\n",
    "def UR_center(trimap):\n",
    "\n",
    "    target = np.where(trimap==128)\n",
    "    index = random.choice([i for i in range(len(target[0]))])\n",
    "    return  np.array(target)[:,index][:2]\n",
    "\n",
    "def load_path(alpha,eps,BG,hard_mode = False):\n",
    "    folders = os.listdir(alpha)\n",
    "    common_paths = []\n",
    "    if hard_mode:\n",
    "        for folder in folders:\n",
    "            if int(folder) in hard_samples: \n",
    "                images = os.listdir(os.path.join(alpha,folder))\n",
    "                common_paths.extend([os.path.join(folder,image) for image in images])\n",
    "    else:\n",
    "        for folder in folders:\n",
    "            #if int(folder)==137:\n",
    "            images = os.listdir(os.path.join(alpha,folder))\n",
    "            common_paths.extend([os.path.join(folder,image) for image in images])\n",
    "    print(common_paths)\n",
    "    alphas_abspath = [os.path.join(alpha,common_path) for common_path in common_paths]\n",
    "    epses_abspath = [os.path.join(eps,common_path) for common_path in common_paths]\n",
    "    BGs_abspath = [os.path.join(BG,common_path)[:-3] + 'jpg' for common_path in common_paths]\n",
    "    return np.array(alphas_abspath),np.array(epses_abspath),np.array(BGs_abspath)\n",
    "\n",
    "def load_data(batch_alpha_paths,batch_eps_paths,batch_BG_paths):\n",
    "    \n",
    "    batch_size = batch_alpha_paths.shape[0]\n",
    "    train_batch = []\n",
    "    images_without_mean_reduction = []\n",
    "    for i in range(batch_size):\n",
    "                \n",
    "        alpha = misc.imread(batch_alpha_paths[i],'L').astype(np.float32)\n",
    "\n",
    "        eps = misc.imread(batch_eps_paths[i]).astype(np.float32)\n",
    "\n",
    "        BG = misc.imread(batch_BG_paths[i]).astype(np.float32)\n",
    "\n",
    "        batch_i,raw_RGB = preprocessing_single(alpha, BG, eps,batch_alpha_paths[i])\t\n",
    "        train_batch.append(batch_i)\n",
    "        images_without_mean_reduction.append(raw_RGB)\n",
    "    train_batch = np.stack(train_batch)\n",
    "    return train_batch[:,:,:,:3],np.expand_dims(train_batch[:,:,:,3],3),np.expand_dims(train_batch[:,:,:,4],3),train_batch[:,:,:,5:8],train_batch[:,:,:,8:],images_without_mean_reduction\n",
    "\n",
    "def generate_trimap(trimap,alpha):\n",
    "\n",
    "    k_size = random.choice(trimap_kernel)\n",
    "    trimap[np.where((ndimage.grey_dilation(alpha[:,:,0],size=(k_size,k_size)) - ndimage.grey_erosion(alpha[:,:,0],size=(k_size,k_size)))!=0)] = 128\n",
    "    #trimap[np.where((ndimage.grey_dilation(alpha[:,:,0],size=(k_size,k_size)) - alpha[:,:,0]!=0))] = 128\n",
    "    return trimap\n",
    "\n",
    "def preprocessing_single(alpha, BG, eps,name,image_size=320):\n",
    "\n",
    "    alpha = np.expand_dims(alpha,2)\n",
    "    trimap = np.copy(alpha)\n",
    "    trimap = generate_trimap(trimap,alpha)\n",
    "\n",
    "    train_data = np.zeros([image_size,image_size,8])\n",
    "    crop_size = random.choice([320,480,620])\n",
    "#    crop_size = 320   \n",
    "    flip = random.choice([0,1])\n",
    "    i_UR_center = UR_center(trimap)\n",
    "    #i_UR_center = [int(alpha.shape[0]/2),int(alpha.shape[1]/2)]\n",
    "    train_pre = np.concatenate([trimap,alpha,BG,eps],2)\n",
    "\n",
    "    if crop_size == 320:\n",
    "        h_start_index = i_UR_center[0] - 159\n",
    "        w_start_index = i_UR_center[1] - 159\n",
    "        tmp = train_pre[h_start_index:h_start_index+320, w_start_index:w_start_index+320, :]\n",
    "        if flip:\n",
    "            tmp = tmp[:,::-1,:]\n",
    "        tmp[:,:,1] = tmp[:,:,1] / 255.0\n",
    "        tmp[:,:,5:] = np.expand_dims(tmp[:,:,1],2)  * tmp[:,:,5:]  # here replace eps with FG\n",
    "        raw_RGB = np.expand_dims(tmp[:,:,1],2)  * tmp[:,:,5:] + np.expand_dims((1. - tmp[:,:,1]),2) * tmp[:,:,2:5]\n",
    "        reduced_RGB = raw_RGB - g_mean\n",
    "        tmp = np.concatenate([reduced_RGB,tmp],2)\n",
    "        train_data = tmp\n",
    "\n",
    "    if crop_size == 480:\n",
    "        h_start_index = i_UR_center[0] - 239\n",
    "        w_start_index = i_UR_center[1] - 239\n",
    "        tmp = train_pre[h_start_index:h_start_index+480, w_start_index:w_start_index+480, :]\n",
    "        if flip:\n",
    "            tmp = tmp[:,::-1,:]\n",
    "        tmp1 = np.zeros([image_size,image_size,8]).astype(np.float32)\n",
    "        tmp1[:,:,0] = misc.imresize(tmp[:,:,0].astype(np.uint8),[image_size,image_size],interp = 'nearest',mode='L').astype(np.float32)\n",
    "        tmp1[:,:,1] = misc.imresize(tmp[:,:,1].astype(np.uint8),[image_size,image_size]).astype(np.float32) / 255.0\n",
    "        tmp1[:,:,2:5] = misc.imresize(tmp[:,:,2:5].astype(np.uint8),[image_size,image_size,3]).astype(np.float32)\n",
    "        tmp1[:,:,5:] = misc.imresize(tmp[:,:,5:].astype(np.uint8),[image_size,image_size,3]).astype(np.float32)\n",
    "        tmp1[:,:,5:] = np.expand_dims(tmp1[:,:,1],2)  * tmp1[:,:,5:]  # here replace eps with FG        \n",
    "        raw_RGB = np.expand_dims(tmp1[:,:,1],2)  * tmp1[:,:,5:] + np.expand_dims((1. - tmp1[:,:,1]),2) * tmp1[:,:,2:5]\n",
    "        reduced_RGB = raw_RGB - g_mean      \n",
    "        tmp1 = np.concatenate([reduced_RGB,tmp1],2)\n",
    "        train_data = tmp1\n",
    "\n",
    "    if crop_size == 620:\n",
    "        h_start_index = i_UR_center[0] - 309\n",
    "        #boundary security\n",
    "        if h_start_index<0:\n",
    "            h_start_index = 0\n",
    "        w_start_index = i_UR_center[1] - 309\n",
    "        if w_start_index<0:\n",
    "            w_start_index = 0\n",
    "        tmp = train_pre[h_start_index:h_start_index+620, w_start_index:w_start_index+620, :]\n",
    "        if flip:\n",
    "            tmp = tmp[:,::-1,:]\n",
    "        tmp1 = np.zeros([image_size,image_size,8]).astype(np.float32)\n",
    "        tmp1[:,:,0] = misc.imresize(tmp[:,:,0].astype(np.uint8),[image_size,image_size],interp = 'nearest',mode='L').astype(np.float32)\n",
    "        tmp1[:,:,1] = misc.imresize(tmp[:,:,1].astype(np.uint8),[image_size,image_size]).astype(np.float32) / 255.0\n",
    "        tmp1[:,:,2:5] = misc.imresize(tmp[:,:,2:5].astype(np.uint8),[image_size,image_size,3]).astype(np.float32)\n",
    "        tmp1[:,:,5:] = misc.imresize(tmp[:,:,5:].astype(np.uint8),[image_size,image_size,3]).astype(np.float32)\n",
    "        tmp1[:,:,5:] = np.expand_dims(tmp1[:,:,1],2)  * tmp1[:,:,5:]  # here replace eps with FG        \n",
    "        raw_RGB = np.expand_dims(tmp1[:,:,1],2)  * tmp1[:,:,5:] + np.expand_dims((1. - tmp1[:,:,1]),2) * tmp1[:,:,2:5]\n",
    "        reduced_RGB = raw_RGB - g_mean      \n",
    "        tmp1 = np.concatenate([reduced_RGB,tmp1],2)\n",
    "        train_data = tmp1\n",
    "    train_data = train_data.astype(np.float32)\n",
    "#    misc.imsave('./train_alpha.png',train_data[:,:,4])\n",
    "    return train_data,raw_RGB\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_alphamatting_data(test_alpha):\n",
    "    rgb_path = os.path.join(test_alpha,'rgb')\n",
    "    trimap_path = os.path.join(test_alpha,'trimap')\n",
    "    alpha_path = os.path.join(test_alpha,'alpha')\t\n",
    "    images = os.listdir(trimap_path)\n",
    "    test_num = len(images)\n",
    "    all_shape = []\n",
    "    rgb_batch = []\n",
    "    tri_batch = []\n",
    "    alp_batch = []\n",
    "    for i in range(test_num):\n",
    "        rgb = misc.imread(os.path.join(rgb_path,images[i]))\n",
    "        trimap = misc.imread(os.path.join(trimap_path,images[i]),'L')\n",
    "        alpha = misc.imread(os.path.join(alpha_path,images[i]),'L')/255.0\n",
    "        all_shape.append(trimap.shape)\n",
    "        rgb_batch.append(misc.imresize(rgb,[320,320,3])-g_mean)\n",
    "        trimap = misc.imresize(trimap,[320,320],interp = 'nearest').astype(np.float32)\n",
    "        tri_batch.append(np.expand_dims(trimap,2))\n",
    "        alp_batch.append(alpha)\n",
    "    return np.array(rgb_batch),np.array(tri_batch),np.array(alp_batch),all_shape,images\n",
    "\n",
    "def load_validation_data(vali_root):\n",
    "    alpha_dir = os.path.join(vali_root,'alpha')\n",
    "    RGB_dir = os.path.join(vali_root,'RGB')\n",
    "    images = os.listdir(alpha_dir)\n",
    "    test_num = len(images)\n",
    "    \n",
    "    all_shape = []\n",
    "    rgb_batch = []\n",
    "    tri_batch = []\n",
    "    alp_batch = []\n",
    "\n",
    "    for i in range(test_num):\n",
    "        rgb = misc.imread(os.path.join(RGB_dir,images[i]))\n",
    "        alpha = misc.imread(os.path.join(alpha_dir,images[i]),'L') \n",
    "        trimap = generate_trimap(np.expand_dims(np.copy(alpha),2),np.expand_dims(alpha,2))[:,:,0]\n",
    "        alpha = alpha / 255.0\n",
    "        all_shape.append(trimap.shape)\n",
    "        rgb_batch.append(misc.imresize(rgb,[320,320,3])-g_mean)\n",
    "        trimap = misc.imresize(trimap,[320,320],interp = 'nearest').astype(np.float32)\n",
    "        tri_batch.append(np.expand_dims(trimap,2))\n",
    "        alp_batch.append(alpha)\n",
    "    return np.array(rgb_batch),np.array(tri_batch),np.array(alp_batch),all_shape,images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
